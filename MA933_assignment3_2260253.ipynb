{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e48e81b8",
   "metadata": {},
   "source": [
    "# MA933 Assignment 3\n",
    "\n",
    "*Student ID: 2260253*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51d1eecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "\n",
    "# built-in statistics function for unbiased variance\n",
    "from statistics import variance\n",
    "\n",
    "# probability distributions\n",
    "from scipy import stats\n",
    "\n",
    "#plotting\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams.update({'font.size': 22})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72c4f95",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a649b",
   "metadata": {},
   "source": [
    "For ease of reproducibility the below cell will generate the 20 realisations $G_{N,p}$ for each $z \\in \\{0.1,0.2,...,3.0\\}$ and $N \\in \\{100,1000\\}$ and combine the computational tasks in parts a,b and c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16560e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [100, 1000]                  # number of nodes\n",
    "zs = np.arange(0.1,3.1,0.1)       # expected degree\n",
    "realisations = 20\n",
    "\n",
    "# average sizes of largest and second largest components\n",
    "L1avg = []\n",
    "L2avg = []\n",
    "\n",
    "# and standard deviations\n",
    "L1err = []\n",
    "L2err = []\n",
    "\n",
    "# average number of edges\n",
    "Eavg = []\n",
    "Eerr = []\n",
    "\n",
    "# average degree\n",
    "davg = []\n",
    "davgerr = []\n",
    "\n",
    "# average local clustering coefficient\n",
    "CCavg = []\n",
    "CCerr = []\n",
    "\n",
    "for N in Ns:\n",
    "    for z in zs:\n",
    "        # probability that an edge is added\n",
    "        p = z/N\n",
    "        \n",
    "        # bins for largest and second largest componenets\n",
    "        L1 = []\n",
    "        L2 = []\n",
    "        \n",
    "        E = []    # number of edges\n",
    "        d = []    # average degree\n",
    "        \n",
    "        if N == 1000:\n",
    "            ccoef = []    # clustering coefficient\n",
    "        \n",
    "        for r in range(realisations):\n",
    "            # generate ER random graph\n",
    "            G = nx.gnp_random_graph(N,p)\n",
    "        \n",
    "            # get the components\n",
    "            Gcc = sorted([G.subgraph(c) for c in nx.connected_components(G)], key = len, reverse=True)\n",
    "\n",
    "            # size of largest and second largest components\n",
    "            L1 += [len(Gcc[0])/N]\n",
    "            L2 += [len(Gcc[1])/N]\n",
    "            \n",
    "            E += [G.number_of_edges()]    # number of edges\n",
    "            d += [2*G.number_of_edges()/N]    # average degree\n",
    "            \n",
    "            # local clustering coefficient\n",
    "            if N == 1000:\n",
    "                coefs = list(nx.clustering(G).values())\n",
    "                ccoef += [sum(coefs)/N]\n",
    "            \n",
    "        L1avg += [sum(L1)/realisations]\n",
    "        L2avg += [sum(L2)/realisations]\n",
    "        \n",
    "        L1err += [np.sqrt(variance(L1))]\n",
    "        L2err += [np.sqrt(variance(L2))]\n",
    "        \n",
    "        Eavg += [sum(E)/realisations]\n",
    "        Eerr += [np.sqrt(variance(E))]\n",
    "        \n",
    "        davg += [sum(d)/realisations]\n",
    "        davgerr += [np.sqrt(variance(d))]\n",
    "        \n",
    "        if N == 1000:\n",
    "            CCavg += [sum(ccoef)/realisations]\n",
    "            CCerr += [np.sqrt(variance(ccoef))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c9246a",
   "metadata": {},
   "source": [
    "**Question 2(a)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da5d570",
   "metadata": {},
   "source": [
    "Below we plot the largest and second largest component mean size scaled by $N$ for each $z$. The size of the largest component appears to follow a logarithmic law and increases with diminishing returns at a similar rate for both values of $N$ as $z$ increases. The size of the second largest component remains rather low for all values of $z$, increasing at a slow rate for approximately $z<1$ before decreasing towards zero for $z>1$. The scaled size of the second largest component is generally higher for $N=100$ over $N=1000$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169d8060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "fig = plt.figure(figsize=(16,12))\n",
    "\n",
    "plt.errorbar(zs, L1avg[:len(zs)], L1err[:len(zs)], color='k', marker='o', mfc='b', ms=10, capsize=6,\n",
    "            label = 'largest, N = 100')\n",
    "plt.errorbar(zs, L1avg[len(zs):], L1err[len(zs):], color='k', marker='s', mfc='b', ms=10, capsize=6,\n",
    "            label = 'largest, N = 1000')\n",
    "plt.errorbar(zs, L2avg[:len(zs)], L2err[:len(zs)], color='k', marker='o', mfc='r', ms=10, capsize=6,\n",
    "            label = '2nd largest, N = 100')\n",
    "plt.errorbar(zs, L2avg[len(zs):], L2err[len(zs):], color='k', marker='s', mfc='r', ms=10, capsize=6,\n",
    "            label = '2nd largest, N = 1000')\n",
    "\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('Average size / $N$')\n",
    "plt.title('Largest and second largest component mean size')\n",
    "plt.xlim([0,3.1])\n",
    "plt.legend(loc=0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f1822",
   "metadata": {},
   "source": [
    "**Question 2(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825369b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.errorbar(zs, CCavg, CCerr, color='k', marker='o', mfc='b', ms=10, capsize=6)\n",
    "\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('Size')\n",
    "plt.title('Average local clustering coefficient $<C_i>$, $N = 1000$')\n",
    "plt.xlim([0,3.1])\n",
    "plt.ylim([0,0.005])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439de551",
   "metadata": {},
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889e26f",
   "metadata": {},
   "source": [
    "**Question 2(c)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4162ae1d",
   "metadata": {},
   "source": [
    "From the lecture material, the expected number of undirected edges $K$ and the average degree $<k>$ are\n",
    "\n",
    "$$\\mathbb{E}[K] = {N\\choose2} p(z) = \\frac{N-1}{2} z$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\mathbb{E}[<k>] = (N-1) p(z) = \\frac{N-1}{N} z$$\n",
    "\n",
    "respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37acec8",
   "metadata": {},
   "source": [
    "Below we have plotted the average number of edges and the average degree as well as their corresponding standard deviation errors according to the relevant 20 realisations for all $z$.\n",
    "\n",
    "With regards to average number of edges, we see both plots increase linearly with $z$ and closely follow their respective theoretical rates. We see the average number of edges for $N=1000$ increase at a greater rate when compared to $N=100$. This can be expected, as the coefficient in the theoretical expectation is $(1000-1)/2 = 499.5$ for $N=1000$ compared to $(100-1)/2 = 49.5$ for $N=100$, roughly ten times smaller.\n",
    "\n",
    "With regards to the average degree, we see both plots increase linearly with $z$ and closely follow their respective theoretical rates. In fact, they increase at nearly the exact same rate. This is because the coefficient in the theoretical expectation is $(1000-1)/1000 = 0.999$ for $N=1000$ compared to $(100-1)/100 = 0.99$ for $N=100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ddcbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting average number of edges\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.errorbar(zs, Eavg[:len(zs)], Eerr[:len(zs)], color='k', marker='o', mfc='b', ms=10, capsize=6,\n",
    "            label = 'N = 100')\n",
    "plt.errorbar(zs, Eavg[len(zs):], Eerr[len(zs):], color='k', marker='s', mfc='r', ms=10, capsize=6,\n",
    "            label = 'N = 1000')\n",
    "plt.plot(zs, ((100-1)/2)*zs, color='g', linewidth=16, alpha=0.4, label='Theoretical')\n",
    "plt.plot(zs, ((1000-1)/2)*zs, color='m', linewidth=16, alpha=0.4, label='Theoretical')\n",
    "\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('Size')\n",
    "plt.title('Average number of edges')\n",
    "plt.xlim([0,3.1])\n",
    "plt.legend(loc=0)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# plotting average degree\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "plt.errorbar(zs, davg[:len(zs)], davgerr[:len(zs)], color='k', marker='o', mfc='b', ms=10, capsize=6,\n",
    "            label = 'N = 100')\n",
    "plt.errorbar(zs, davg[len(zs):], davgerr[len(zs):], color='k', marker='s', mfc='r', ms=10, capsize=6,\n",
    "            label = 'N = 1000')\n",
    "plt.plot(zs, ((100-1)/100)*zs, color='g', linewidth=16, alpha=0.4, label='Theoretical')\n",
    "plt.plot(zs, ((1000-1)/1000)*zs, color='m', linewidth=16, alpha=0.4, label='Theoretical')\n",
    "\n",
    "plt.xlabel('$z$')\n",
    "plt.ylabel('Size')\n",
    "plt.title('Average degree')\n",
    "plt.xlim([0,3.1])\n",
    "plt.legend(loc=0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a013bc",
   "metadata": {},
   "source": [
    "**Question 2(d)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067df44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the degree distribution of a graph\n",
    "def degree_distribution(G):\n",
    "    vk = dict(G.degree())\n",
    "    vk = list(vk.values())  \n",
    "    vk = np.array(vk)        # store degree values in array\n",
    "    \n",
    "    maxk = np.max(vk)\n",
    "    k = np.arange(0,maxk+1) # possible values of k\n",
    "    \n",
    "    pk = np.zeros(maxk+1) # degree distribution p(k)\n",
    "    for i in vk:\n",
    "        pk[i] = pk[i] + 1\n",
    "    pk = pk/sum(pk) # the sum of the elements of P(k) must to be equal to one\n",
    "    \n",
    "    return k,pk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c894421",
   "metadata": {},
   "source": [
    "Simulating 20 new realizations for $N = 1000$ and $z = 1.8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927beb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "z = 1.8\n",
    "p = z/N\n",
    "\n",
    "# degree distribution\n",
    "ks = np.arange(0,16)\n",
    "degdist = np.zeros(16)\n",
    "\n",
    "for r in range(realisations):\n",
    "    # generate ER random graph\n",
    "    G = nx.gnp_random_graph(N,p)\n",
    "    dist = degree_distribution(G)[1]\n",
    "    \n",
    "    for i in range(len(dist)):\n",
    "        degdist[i] += dist[i] \n",
    "\n",
    "degdist = degdist/realisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0947ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisdist = stats.poisson.pmf(ks, mu=z)\n",
    "\n",
    "# plotting\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.bar(ks, degdist, alpha=0.7)\n",
    "plt.scatter(ks, degdist, s=100, label='Observed distribution')\n",
    "plt.plot(ks, poisdist, 'k--', label='Pois($z$) distribution')\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"$p(k)$\")\n",
    "plt.title(\"Degree distribution\")\n",
    "plt.legend(loc=0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbe8960",
   "metadata": {},
   "source": [
    "The observed degree distribution from our 20 realizations closely matches the probability distribution of a Poisson random variable with rate $z = 1.8$.\n",
    "\n",
    "This is because for an ER graph, the degree distribution follows $k_i \\sim \\textrm{Binomial}(N-1,p)$. However, for $N-1 >> 1$ and $p << 1$ we know that the Binomial distribution is approximately a Poisson distribution $\\sim \\textrm{Pois}(\\lambda)$ with rate parameter $\\lambda = (N-1)p \\approx z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3997b125",
   "metadata": {},
   "source": [
    "**Question 2(e)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce1314",
   "metadata": {},
   "source": [
    "Simulating new realisations for $z \\in \\{0.5,1.5,5,10\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaacd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = [0.5, 1.5, 5, 10]\n",
    "E = np.zeros((realisations,N))\n",
    "avg_evals = np.zeros((len(zs),N))\n",
    "\n",
    "j = 0\n",
    "for z in zs:\n",
    "    p = z/N\n",
    "    \n",
    "    for r in range(realisations):\n",
    "        G = nx.gnp_random_graph(N,p)       # generate the graphs\n",
    "        A = nx.to_numpy_matrix(G)          # find adjacency matrix\n",
    "        evals, evecs = np.linalg.eig(A)    # calculate eigenvalues\n",
    "        E[r,:] = np.sort(evals)            # sort in order\n",
    "\n",
    "    avg_evals[j,:] = np.mean(E,axis=0)  #average the e'values over the realisations\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44895160",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = ['b','r','g','y']\n",
    "\n",
    "for i in range(len(zs)):\n",
    "    fig = plt.figure(figsize = (12,8))\n",
    "    \n",
    "    # find the spectral density using a kernel density estimate \n",
    "    spectral_density = stats.gaussian_kde(avg_evals[i,:], bw_method = 0.05)\n",
    "\n",
    "    #plot the density\n",
    "    lambs = np.linspace(avg_evals[i,:].min(), avg_evals[i,:].max(), N)\n",
    "    plt.plot(lambs, spectral_density(lambs), color=cols[i])\n",
    "    \n",
    "    plt.xlabel('$\\lambda$')\n",
    "    plt.ylabel('$\\\\rho(\\lambda)$')\n",
    "    plt.title('Spectral Density, $z = %.1f$' % zs[i])\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f638736",
   "metadata": {},
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6100be5a",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbeb1e3",
   "metadata": {},
   "source": [
    "For ease of reproducibility the below cell will generate the 20 realisations of the Barabasi-Albert model for $m = m_0 = 5, \\, N = 1000$ and combine the computational tasks in parts a,b and c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b869a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this implementation m0 = m.\n",
    "\n",
    "m = 5      # number of edges added each time (preferential attachment) (also the number of initial nodes)\n",
    "N = 1000   # total number of nodes at the end\n",
    "realisations = 20\n",
    "\n",
    "# degree distribution\n",
    "degdist = np.zeros(N)\n",
    "\n",
    "# eigenvalues and their average\n",
    "E = np.zeros((realisations,N))\n",
    "avg_evals = np.zeros(N)\n",
    "\n",
    "for r in range(realisations):\n",
    "    # initialization is a graph with with m nodes and no edges.\n",
    "    G = nx.barabasi_albert_graph(N, m) \n",
    "    dist = degree_distribution(G)[1]\n",
    "    \n",
    "    for i in range(len(dist)):\n",
    "        degdist[i] += dist[i] \n",
    "    \n",
    "    A = nx.to_numpy_matrix(G)          # find adjacency matrix\n",
    "    evals, evecs = np.linalg.eig(A)    # calculate eigenvalues\n",
    "    E[r,:] = np.sort(evals)            # sort in order\n",
    "\n",
    "# aquiring the non-zero end of tail and adjusting the length of degdist accordingly\n",
    "kmax = np.nonzero(degdist)[0].max()\n",
    "degdist = degdist[:kmax+1]/realisations\n",
    "\n",
    "avg_evals = np.mean(E,axis=0)  #average the eigenvalues over the realisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09778f8f",
   "metadata": {},
   "source": [
    "**Question 3(a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47aa8f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = np.arange(0,kmax+1)\n",
    "alpha = 2    # power-law coefficient\n",
    "\n",
    "# plotting\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "plt.bar(ks, degdist, alpha=0.7)\n",
    "plt.scatter(ks, degdist, s=100, label='Observed distribution')\n",
    "plt.plot(ks[2:], [alpha*i**-3 for i in range(2,kmax+1)], 'k--', label='%.1f $n^{-2}$' % alpha)\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel(\"$k$\")\n",
    "plt.ylabel(\"$p(k)$\")\n",
    "plt.title(\"Degree distribution\")\n",
    "plt.legend(loc=0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7444da6",
   "metadata": {},
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2900e6",
   "metadata": {},
   "source": [
    "**Question 3(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a2a6cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e22edcc5",
   "metadata": {},
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe2fa94",
   "metadata": {},
   "source": [
    "**Question 3(c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9daa8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting\n",
    "fig = plt.figure(figsize = (12,8))\n",
    "    \n",
    "# find the spectral density using a kernel density estimate \n",
    "spectral_density = stats.gaussian_kde(avg_evals, bw_method = 0.05)\n",
    "\n",
    "#plot the density\n",
    "lambs = np.linspace(avg_evals.min(), avg_evals.max(), N)\n",
    "plt.plot(lambs, spectral_density(lambs), color='b', label='Observed')\n",
    "    \n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('$\\\\rho(\\lambda)$')\n",
    "plt.title('Spectral Density')\n",
    "plt.legend(loc=0)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f8611",
   "metadata": {},
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323dbdc1",
   "metadata": {},
   "source": [
    "$$\\[k_{nn,i}^{w} = \\frac{1}{s_i} \\sum_{j \\in N(i)} w_{ij} k_j\\]$$\n",
    "\n",
    "where $\\(s_i\\)$ is the weighted degree of node $\\(i\\)$, $\\(w_{ij}\\)$ is the weight of the edge that links $\\(i\\)$ and $\\(j\\)$, and $\\(N(i)\\)$ are the neighbors of node $\\(i\\)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e787d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = nx.gnp_random_graph(100,0.1)\n",
    "np.array(list(nx.clustering(G).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185bddec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
